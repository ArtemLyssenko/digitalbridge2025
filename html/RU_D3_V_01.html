
<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Гендерные предубеждения и регулирование в сфере ИИ — Digital Bridge 2025</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
 <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Roboto', sans-serif;
            background: #10132a;
            background-image: radial-gradient(
                600px 500px at 15% 10%,
                rgba(108, 186, 255, 0.18),
                transparent 70%
              ),
              radial-gradient(
                800px 600px at 85% 20%,
                rgba(155, 109, 255, 0.18),
                transparent 70%
              ),
              radial-gradient(
                900px 700px at 50% 90%,
                rgba(33, 212, 253, 0.15),
                transparent 70%
              );
            color: #f5f7ff;
            padding: 1.5rem;
            line-height: 1.6;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            background: #1c2245;
            border: 1px solid rgba(255, 255, 255, 0.12);
            border-radius: 16px;
            padding: 2rem;
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.35);
        }
        .back-link {
            display: inline-block;
            color: #6cbaff;
            text-decoration: none;
            margin-bottom: 2rem;
            font-weight: 600;
            padding: 0.5rem 1rem;
            border: 1px solid rgba(108, 186, 255, 0.3);
            border-radius: 8px;
            transition: all 0.3s ease;
        }
        .back-link:hover { 
            background: rgba(108, 186, 255, 0.1);
            border-color: #6cbaff;
        }
        h1 {
            font-size: 2rem;
            margin-bottom: 1rem;
            background: linear-gradient(90deg, #6cbaff, #9b6dff);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .content h2 {
            color: #6cbaff;
            margin-top: 2rem;
            margin-bottom: 1rem;
            font-size: 1.5rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 1px;
            position: relative;
            padding-left: 16px;
        }
        .content h2::before {
            content: "";
            position: absolute;
            left: 0;
            top: 50%;
            transform: translateY(-50%);
            height: 60%;
            width: 4px;
            border-radius: 2px;
            background: linear-gradient(#6cbaff, #9b6dff);
        }
        .content p {
            margin-bottom: 1rem;
            color: #f5f7ff;
        }
        .content ul {
            margin-left: 2rem;
            margin-bottom: 1rem;
            list-style: none;
        }
        .content li {
            margin-bottom: 0.5rem;
            color: #f5f7ff;
            position: relative;
        }
        .content li::before {
            content: "";
            position: absolute;
            left: -20px;
            top: 50%;
            transform: translateY(-50%);
            width: 8px;
            height: 8px;
            border-radius: 28%;
            background: radial-gradient(circle at top left, #6cbaff, #9b6dff);
            box-shadow: 0 0 6px rgba(155, 109, 255, 0.6);
        }
        
        .speakers {
            margin: 2rem 0;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .speaker-badge {
            display: flex;
            align-items: flex-start;
            gap: 8px;
            padding: 1rem 1.5rem;
            font-size: 14px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        .speaker-name {
            font-weight: 600;
            color: #fff;
        }
        
        .speaker-role {
            color: #a9afc9;
            font-size: 14px;
        }
        
        blockquote {
            margin: 1rem 0;
            padding: 1rem 1.5rem;
            border-left: 4px solid #21d4fd;
            background: #27305a;
            border-radius: 10px;
            color: #f5f7ff;
            font-style: italic;
            box-shadow: inset 0 0 6px rgba(33, 212, 253, 0.3);
        }
        
        .author {
            font-style: normal;
            color: #6cbaff;
            font-weight: 600;
        }
        
        .note {
            max-width: 900px;
            margin: 2rem auto 0;
            padding: 1.5rem 2rem;
            background: rgba(255, 215, 0, 0.08);
            border-radius: 12px;
            font-size: 0.9rem;
            color: #fff6c2;
            line-height: 1.6;
            border: 1px solid rgba(255, 215, 0, 0.2);
            box-shadow: 0 0 8px rgba(255, 215, 0, 0.2);
        }
        
        .note strong {
            color: #ffd700;
            font-weight: 600;
        }
    </style>
</head>
<body>
  <div class="container">
    <a href="../index.html" class="back-link">← Назад к расписанию</a>
    <h1>Гендерные предубеждения и регулирование в сфере ИИ</h1>

    <div class="speakers">
      
  <div class="speaker-badge">
    <div>
      <span class="speaker-name">Асем</span>
      <span class="speaker-role"> — модератор сессии</span>
    </div>
  </div>


  <div class="speaker-badge">
    <div>
      <span class="speaker-name">Юлдашева Ильмира</span>
      <span class="speaker-role"> — Партнёр юридической фирмы Zan Hub (г. Алматы)</span>
    </div>
  </div>


  <div class="speaker-badge">
    <div>
      <span class="speaker-name">Ткаченко Алена</span>
      <span class="speaker-role"> — Вице-президент по глобальным рынкам Sergek Group</span>
    </div>
  </div>


  <div class="speaker-badge">
    <div>
      <span class="speaker-name">Акинсанми Тити</span>
      <span class="speaker-role"> — Лидер общественного мнения в области государственной политики цифровой экономики, Партнёрство за глобальную цифровую инклюзивность, Член наблюдательного совета Форума технологической дипломатии</span>
    </div>
  </div>


  <div class="speaker-badge">
    <div>
      <span class="speaker-name">Мадина Дусмагамбетова</span>
      <span class="speaker-role"> — Co-founder Soft Creation, Senior member of WOMEN IN TECH, Руководитель программы Women in innovations and AI</span>
    </div>
  </div>


  <div class="speaker-badge">
    <div>
      <span class="speaker-name">Жанара</span>
      <span class="speaker-role"> — Эксперт по биометрии и цифровой идентификации; участвовала в запуске Digital ID на eGov.kz</span>
    </div>
  </div>

    </div>

    <div class="content">
      <h2>Аннотация</h2>
      <p>Панель обсудила два акцента: дефицит женщин в ИИ и системные гендерные/этнические искажения данных и алгоритмов; а также практики и регулирование ИИ — от стандартов качества данных и bias-аудитов до риск-ориентированного подхода и human-in-the-loop. Участницы настаивали на инклюзивных командах по всей цепочке — от образования до корпоративных центров ИИ, и предложили механизмы: AI impact assessment, право на объяснение, этический совет по ИИ, песочницы для инноваций. По итогам объявлена подготовка декларации с рекомендациями правительству и AI Council.</p>

      <h2>Цели</h2>
      <ul><li>Снизить гендерные и иные предвзятости в данных, моделях и внедрении ИИ</li>
<li>Увеличить долю женщин на всех уровнях AI-пайплайна (образование, R&D, продукт, управление)</li>
<li>Внедрить стандарты качества данных, обязательные bias-аудиты и AI impact assessment в госсекторе</li>
<li>Закрепить риск-ориентированное регулирование с человеческим контролем и правом на объяснение</li>
<li>Создать устойчивые программы просвещения, (ре)скиллинга и роль-моделей для девушек и женщин</li></ul>

      <h2>Основные вопросы</h2>
      <ul><li>Какие системные меры в образовании и корпоративной практике реально увеличат долю женщин в ИИ?</li>
<li>Как спроектировать регуляторную политику, чтобы исключить дискриминационные исходы (например, в биометрии) уже на этапе тестирования и внедрения?</li>
<li>Какие стандарты по данным (качество, приватность, управление) и механизмы прозрачности необходимы в Казахстане прямо сейчас?</li>
<li>Как совместить стимулирование инноваций (песочницы) с ответственностью и безопасностью (high-risk классификация, human-in-the-loop)?</li></ul>

      <h2>Ключевые тезисы</h2>
      <ul><li>ИИ не нейтрален: он отражает данные и предположения создателей; разнообразие команд снижает риски искажений.</li>
<li>Глобально лишь ~22% специалистов в ИИ — женщины; в Казахстане этот показатель ещё ниже, что усиливает риск bias в продуктах.</li>
<li>Инклюзивность нужна на всех этапах: сбор и разметка данных, дизайн, разработка, тестирование по подгруппам, внедрение и аудит.</li>
<li>Данные требуют управления: стандарты качества, репрезентативность, прозрачные методологии, отчётность по использованию и удалению.</li>
<li>Обязательные bias-аудиты и AI impact assessment (в т.ч. социально-экономический и по правам человека) — базовые механизмы в госсекторе.</li>
<li>Риск-ориентированный подход к ИИ с реестром высокорисковых систем и обязательным human-in-the-loop снижает ущерб от ошибок.</li>
<li>Право на объяснение и понятная пользователю прозрачность решений критичны, особенно при доступе к услугам и в биометрии.</li>
<li>Регуляторные песочницы позволяют тестировать инновации на переднем крае в контролируемых условиях без торможения прогресса.</li>
<li>Роль-модели (Fei-Fei Li, Mira Murati и др.) и ранняя экспозиция STEM/STEAM повышают вовлечённость девушек.</li>
<li>Корпоративные стимулы и метрики (например, дифференцированные эффекты по полу) помогают выявлять и исправлять bias там, где «деньги и данные» показывают выгоду инклюзивности.</li></ul>

      <h2>Цитаты</h2>
      
  <blockquote>“We tend to design in ways that replicates the world of the innovator.” — <span class="author">Акинсанми Тити</span></blockquote>


  <blockquote>“Common sense is not so common — it's a luxury.” — <span class="author">Ткаченко Алена</span></blockquote>


  <blockquote>“В Казахстане женщин, кто занимается искусственным интеллектом, практически нет… точно не больше пяти процентов.” — <span class="author">Мадина Дусмагамбетова</span></blockquote>


  <blockquote>“Мы не допустим полностью автоматические продукты ИИ, где не будет контроля человека.” — <span class="author">Юлдашева Ильмира</span></blockquote>


      <h2>Выводы</h2>
      <ul><li>Без признания и адресации гендерных и этнических предвзятостей ИИ будет масштабировать офлайн-стереотипы онлайн.</li>
<li>Системное регулирование ИИ должно сочетать стандарты данных, аудит, прозрачность и человеческий контроль с поддержкой инноваций через песочницы.</li>
<li>Образование и рескиллинг — непрерывная основа для расширения участия женщин и усиления компетенций у разработчиков и регуляторов.</li></ul>

      <h2>Принятые решения</h2>
      <ul><li>Подготовить и направить в правительство, AI Council и профильные ведомства декларацию с рекомендациями по этике и регулированию ИИ.</li>
<li>Рекомендовать введение обязательных bias-аудитов и AI impact assessment для государственных систем ИИ, начиная с биометрии.</li>
<li>Поддержать создание национального совета по этике ИИ с обязательным гендерным балансом и участием индустрии, академии и гражданского общества.</li></ul>

      <h2>Action Items</h2>
      <ul><li>Сформировать рабочую группу (Women in Tech Kazakhstan, Zang Hub и отраслевые эксперты) для консолидации предложений и материалов панели.</li>
<li>Разработать пакет методик: стандарты качества данных и тестирование по подгруппам, процедуры AI Impact Assessment, требования human-in-the-loop и право на объяснение, этические базовые требования к государственным закупкам ИИ.</li>
<li>Согласовать с Минцифры, AI Council, Администрацией Президента и регуляторами финсектора дорожную карту пилотного внедрения bias-аудитов.</li>
<li>Запустить пилотные независимые bias-аудиты 2–3 высокорисковых гос-систем (биометрическая идентификация, скоринг) и опубликовать отчёты.</li>
<li>Расширить образовательные треки и рескиллинг для женщин и команд регуляторов; подготовить корпоративные рекомендации по инклюзивным AI-командам и центрам компетенций.</li></ul>

      <h2>Источники</h2>
      <ul><li>World Economic Forum: Women in AI (около 22% специалистов — женщины)</li>
<li>MIT Media Lab — исследование по распознаванию лиц и гендерно-этническим искажениям (Gender Shades)</li>
<li>UNESCO Recommendation on the Ethics of Artificial Intelligence (2021)</li>
<li>EU AI Act — риск-ориентированный подход и классификация систем</li>
<li>eGov.kz Digital ID (биометрическая идентификация, Казахстан)</li>
<li>Инициативы Фэй-Фэй Ли по 3D-данным</li>
<li>Mira Murati (OpenAI) — роль-модель и практика в LLM</li>
<li>Android/Google: функции корректной передачи тона кожи (упомянуто как True Tone)</li>
<li>Women in Tech Kazakhstan / WomenEdTech — образовательные программы</li>
<li>Tech Diplomacy Forum; Digital Inclusion Partnership</li></ul>
    </div>
  </div>

  <div class="note">
    <strong>Примечание:</strong> Данный текст подготовлен с использованием технологий искусственного интеллекта на основе живой речи спикеров международного форума Digital Bridge 2025. Он может содержать отдельные ошибки или неточности и не является официальной стенограммой. Для подтверждения фактов и деталей рекомендуется обращаться к официальным материалам форума.
  </div>
</body>
</html>
